# DD2424 Deep Learning in Data Science - Assignment 2

```python, term=True, echo=False
%matplotlib inline
import os
import sys
sys.path.append(os.getcwd() + '/..')
from assignment2 import *
```

## Introduction
The goal of this assignment is to train and evaluate the performance of a *two layer neural network* in order to
classify images from the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset.


## Computing the gradient

Before continuing we first have to verify that the gradients computed are sufficiently accurate. A comparsion is therefore made between
the analytically computed gradients and the corresponding gradients computed numerically, for each layer in the network.
Because it is computationally expensive to compute the cost for all entries in the weight matrices using the numerical methods we'll reduce the number of images and their dimensionality when computing the gradients for this comparison.
The dimensionality of the images are brought down from 3072 to 100. We're also only using 20 samples and setting the tolerance to 1e-5.

The relative error between the analytical gradient and the gradients computed with the *Finite* and *Central-*difference methods are shown in the table below,

```python, term=True, echo=False, result='tex', wrap=False
check_gradient(dimensions=100, batchSize=20)
```
 
A quick sanity check is also done by training the model for 200 epochs with no regularization and a learning rate set to 0.01.
From this we expect the model to become very overfitted to the training data and therefore have a very low loss for the training set.
The results are shown in the figure below

![](figures/sanityCheck_overfitting.png)

We're now quite confident in that the analytical gradient is sufficiently accurate since we've verified that the differences between the analytical and numerical gradients are small and
that we're able to achieve a very overfitted model with a low loss on the training data. As such we'll proceed.

## Train the network on a batch of data

The network was then trained for one cycle with the given parameter values.

```python, term=True, echo=False,
report(l=0.01, cycles=1, n_s=500)
```

Now we'll train for 3 cycles.
```python, term=True, echo=False,
report(l=0.01, cycles=3, n_s=800)
```

The cyclical pattern of the learning rate is clearly visible in both the accuracy and loss/cost plots.
It seems to work well because by varying the magnitude of the learning rate, we're periodically taking larger "steps" when updating the weights and biases, which may allow us
to move away from a local minimum of the cost function. As such, the neural network doesn't run the same risk of getting stuck at a local minima during the gradient descent and 
should therefore be able to achieve better performance in most cases.

### Coarse search for *good* regularization parameter values

We'll now perform a *coarse* search for a good value of the regularization parameter. Samples for regularization parameters
are generated with a uniform distribution over set range of possible values. The regularization parameters are generated with the following code

```
lambdas = lmin + (lmax - lmin)*np.random.uniform(size=num_parameters)
lambdas = np.power(10, lambdas)
```

Where the bounds were set as ```lmin=-5``` and ```lmax=-1``` and the number of regularization parameters to test were set to 
```num_parameters=8```. For each regularization parameter, a network was initialised and trained for two cycles. The performance of each network was then
recorded to produce the table below.

```python, term=True, echo=False,
parameter_search(-1, -5, filename='coarse')
```

From this we can then identify the value of lambda that gave the best accuracy on the validation data.
Then, we choose a smaller range and perform a finer search to see if we can do better. A decent smaller range seems to be a value between
0.005 and 0.05.


### Fine search for *good* values for the regularization parameter

The same prodedure is done as for the coarse search but this time using a smaller range, decided by the results from the coarse search.
The bounds were set to ```lower_limit=-2``` and ```upper_limit=-3``` and the number of parameters to test was 10.
This produced the table below.

```python, term=True, echo=False,
parameter_search(-2, -3, filename='fine')
```



### Train the network on all training data

Now that we've found a good value for the regularization parameter we'll train the network
on all the training data (batches 1-5) except for 1000 examples which will be reserved as a validation set.
The training is then done for 3 cycles using the best regularization paramater value (0.005124) found during the parameter search.

```python, term=True, echo=False,
report(l=0.005124, cycles=3, n_s=800, num_training_batches=5)
```


## Optimize the performance of the network
Now we make some changes to see if we can increase the performance of the network. There are many possible options
to consider but I will mainly focus on

* Implement dropout
* Investigate if more hidden nodes improves the accuracy on the test data
* Add noise to the training samples


### Dropout
During training we'll kill the activations of neurons with a probability p for each hidden layer. By "killing" a neuron we'll
set its output to zero, effectively killing the signal from that neuron, preventing it from propagating further in the network.
This is a strategy used for regularization of neural networks.

Running dropout using ``p=0.5`` on a neural network with 50 nodes in the hidden layer we obtain the following results.
```python, term=True, echo=False,
report(l=0.005124, cycles=3, n_s=800, num_nodes=50, dropout=0.5, num_training_batches=5)
```


### Adding more nodes to the hidden layer

We'll first increase the number of nodes from 50 to 100 in the hidden layer.
```python, term=True, echo=False,
report(l=0.005124, cycles=3, n_s=800, num_nodes=100, num_training_batches=5)
```

Then 
```python, term=True, echo=False,
report(l=0.005124, cycles=3, n_s=800, num_nodes=500, num_training_batches=5)
```
Increasing the number of nodes seems to have helped improve the accuracy on the test data quite a bit.
Since I've also implemented support for more than two layers I'll include a run with three hidden layers.

```python, term=True, echo=False,
report(l=0.005124, cycles=3, n_s=800, num_nodes=(100, 50, 25), num_training_batches=5)
```

### Add noise to training data
By adding noise to the data will make it more difficult for the network to make a precise fit
to the training data and will therefore reduce the risk of overfitting the model.

Add gaussian noise with mean 0 and standard deviation 0.01.
```python, term=True, echo=False,
report(l=0.005124, cycles=3, n_s=800, num_training_batches=5, noise='gaussian')
```

Add salt&pepper noise
```python, term=True, echo=False,
report(l=0.005124, cycles=3, n_s=800, num_training_batches=5, noise='s&p')
```

## Find *good* values for ```eta_min``` and ```eta_max```

In order to find some decent values for our maximum and minimum learnin rate we'll perform a "Learning rate range test".
The idea is to let the model run for half a cycle, allowing the learning rate to linearly increase from the minimum to the maximum value.
By recording the accuracies achieved for different learning rates and then plotting these against each other. We then look at where
the accuracy first starts to increase and where it starts to level out, becomes jagged or even declines. These two points are typically considered
to be good upper and lower bounds for the learning rate.

For our particular case we obtain
```python, term=True, echo=False,
search_lr(1e-5, 0.1)
```
Juding by this plot it seems to be reasonable to set ```eta_min = 1e-5``` and ```eta_max = 0.07```

We'll finally train a model that uses the best values found for the regularization parameter and the learning rate boundary.
```python, term=True, echo=False,
report(l=0.005124, cycles=3, n_s=800, eta_min=1e-5, eta_max=0.07, num_training_batches=5)
```

And for reference, this is the network with the default boundaries for the learning rate.

```python, term=True, echo=False,
report(l=0.005124, cycles=3, n_s=800, num_training_batches=5)
```